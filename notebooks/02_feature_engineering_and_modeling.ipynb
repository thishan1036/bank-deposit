{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1baa9f",
   "metadata": {},
   "source": [
    "## **Boosting Marketing Efficiency: Targeted Bank Campaign by Customer Subscription Behavior**\n",
    "\n",
    "**Overall Project Objective:** \n",
    "\n",
    "Develop a data-driven marketing strategy that maximizes return on investment (ROI) by identifying optimal trade-off between broad customer outreach and precision marketing using predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964941a",
   "metadata": {},
   "source": [
    "**Notebook 2 of 3: Feature Engineering & Predictive Modeling**\n",
    "\n",
    "This notebook covers the core technical steps of the predictive modeling pipeline. \n",
    "\n",
    "The primary goals are to:\n",
    "- Prepare the cleaned data for machine learning through feature engineering.\n",
    "- Build and evaluate several classification models.\n",
    "- Identify the best-performing model for predicting term deposit subscriptions.\n",
    "- Analyze the precision-recall trade-off to inform the final strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22222c",
   "metadata": {},
   "source": [
    "### **Data Load**\n",
    "\n",
    "Simple data and libraries load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f1230ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0256b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/bank_cleaned.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9e946",
   "metadata": {},
   "source": [
    "**-Data Overview-**\n",
    "\n",
    "The specific file used is 'bank_cleaned.csv,' which is the cleaned and imputed output from notebook 1. \n",
    "\n",
    "Data at a glance:\n",
    "- Dataset: bank_cleaned.csv\n",
    "- Observations: 4,521\n",
    "- Variables: 17 (pre-feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024c4561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown_outcome</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown_outcome</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown_outcome</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "       contact  day month  duration  campaign  pdays  previous  \\\n",
       "0     cellular   19   oct        79         1     -1         0   \n",
       "1     cellular   11   may       220         1    339         4   \n",
       "2     cellular   16   apr       185         1    330         1   \n",
       "3  unspecified    3   jun       199         4     -1         0   \n",
       "4  unspecified    5   may       226         1     -1         0   \n",
       "\n",
       "          poutcome   y  \n",
       "0  unknown_outcome  no  \n",
       "1          failure  no  \n",
       "2          failure  no  \n",
       "3  unknown_outcome  no  \n",
       "4  unknown_outcome  no  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dc78058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cleaned Data ---\n",
      "\n",
      "Dataset shape: (4521, 17)\n",
      "\n",
      "--- Missing Values Check ---\n",
      "\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# verify loaded data\n",
    "print(\"--- Cleaned Data ---\\n\")\n",
    "print(f\"Dataset shape: {df.shape}\\n\")\n",
    "print(\"--- Missing Values Check ---\\n\") \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa170c",
   "metadata": {},
   "source": [
    "*The dataset contains no missing values with 4,521 observations and 17 variables (16 input variables and 1 output variable)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d8580",
   "metadata": {},
   "source": [
    "### **Feature Engineering**\n",
    "\n",
    "The feature engineering process involves three primary steps:\n",
    "1. **Feature removal:** several columns will be removed before training the model to improve performance:\n",
    "\n",
    "    - Data leakage features: The features identified as source of data leakage ('duration', 'campaign') will be dropped.\n",
    "    \n",
    "    - Low-impact variable: The 'day' variable will be excluded. As seasonality impact is already being analyzed by 'month' variable, the specific day is unlikely to provide a meaningful signal and may introduce more noise than a valuable relationship with the outcome.\n",
    "\n",
    "2. **Categorical variables conversion:** For binary categorical variables, we will use binary endocing to convert them into a numerical format (1s and 0s) that machine learning models can process.\n",
    "\n",
    "3. **Encoding categorical variables:** For multi-class categorical variables, we will apply one-hot encoding. This technique converts each feature into multiple new binary columns, preventing the model from assuming a false ordinal relationship between the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7464e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep original clean df intact\n",
    "df_model = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845264d1",
   "metadata": {},
   "source": [
    "**Feature Removal**\n",
    "\n",
    "*'duration', 'campaign', 'day'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55522035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Remaining Variables ---\n",
      "\n",
      "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'month', 'pdays', 'previous', 'poutcome', 'y']\n"
     ]
    }
   ],
   "source": [
    "# drop variables (duration, campaign, day)\n",
    "exclude_cols = ['duration', 'campaign', 'day']\n",
    "df_model = df_model.drop(columns=exclude_cols)\n",
    "print(\"--- Remaining Variables ---\\n\")\n",
    "print(df_model.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487fc4d",
   "metadata": {},
   "source": [
    "**Categorical Variables Conversion**\n",
    "\n",
    "*'y', 'default', 'housing', 'loan'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2dc4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Binary Variables Mapped ---\n",
      "\n",
      "   y  default  housing  loan\n",
      "0  0        0        0     0\n",
      "1  0        0        1     1\n",
      "2  0        0        1     0\n",
      "3  0        0        1     1\n",
      "4  0        0        1     0\n"
     ]
    }
   ],
   "source": [
    "binary_values = {'yes': 1, 'no': 0}\n",
    "\n",
    "df_model['y'] = df_model['y'].map(binary_values)\n",
    "df_model['default'] = df_model['default'].map(binary_values)\n",
    "df_model['housing'] = df_model['housing'].map(binary_values)\n",
    "df_model['loan'] = df_model['loan'].map(binary_values)\n",
    "\n",
    "print(\"--- Binary Variables Mapped ---\\n\")\n",
    "print(df_model[['y','default','housing','loan']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc09edef",
   "metadata": {},
   "source": [
    "**Multi-Class Categorical Variables Encoding**\n",
    "\n",
    "*'job', 'marital', 'education', 'contact', 'month', 'poutcome'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fc1c733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Multi-Class Variables Encoded ---\n",
      "\n",
      "New dataset shape: (4521, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  balance  housing  loan  pdays  previous  y  job_blue-collar  \\\n",
       "0   30        0     1787        0     0     -1         0  0            False   \n",
       "\n",
       "   job_entrepreneur  ...  month_jul  month_jun  month_mar  month_may  \\\n",
       "0             False  ...      False      False      False      False   \n",
       "\n",
       "   month_nov  month_oct  month_sep  poutcome_other  poutcome_success  \\\n",
       "0      False       True      False           False             False   \n",
       "\n",
       "   poutcome_unknown_outcome  \n",
       "0                      True  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_cols = ['job','marital','education','contact','month','poutcome']\n",
    "df_model = pd.get_dummies(data=df_model, columns=multi_cols, drop_first=True)\n",
    "\n",
    "print(\"--- Multi-Class Variables Encoded ---\\n\")\n",
    "print(\"New dataset shape:\", df_model.shape)\n",
    "df_model.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cbd530",
   "metadata": {},
   "source": [
    "This section has transformed cleaned dataset into a model-ready, fully numeric format.\n",
    "\n",
    "- Feature exclusion: 'Duration' and 'campaign' variables were droppted to prevent data leakage, and the 'day' variable was dropped to minimize data noise.\n",
    "\n",
    "- Binary encoding: The target variable 'y' and the binary features ('default', 'housing', 'loan') were converted from yes/no to 1/0.\n",
    "\n",
    "- One-hot encoding: The 6 multi-class categorical features were converted into numeric dummy variables.\n",
    "\n",
    "The final dataset is fully numeric and is ready to be split for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d94371",
   "metadata": {},
   "source": [
    "### **Data Split & Feature Scaling**\n",
    "\n",
    "Before training, the data will be prepared using a two-step process to ensure reliable model evaluation and performance.\n",
    "\n",
    "1. **Stratified data split:** The dataset will be split into an 80% training set and 20% test set. Because the dataset is imbalanced (approximately 11.5% positive class), we will use a **stratified split.** This ensures the proportion of subscribers is the same in both the training and test sets, which is a best practice for imbalanced classification problems.\n",
    "\n",
    "2. **Feature scaling:** After splitting the data, all numerical variables will be scaled. This step is neccessary to prevent numerical instability in distance-based algorithms like SMOTE and is performed after the split to avoid data leakage from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0e1c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Splitting Verification ---\n",
      "\n",
      "Training set shape: (3616, 37)\n",
      "Testing set shape: (905, 37)\n",
      "\n",
      "Subscription rate in original dataset: 11.52%\n",
      "Subscription rate in training dataset: 11.53%\n",
      "Subscription rate in testing dataset: 11.49%\n"
     ]
    }
   ],
   "source": [
    "# 'y' is target variable\n",
    "# rest will be input variables\n",
    "y = df_model['y']\n",
    "X = df_model.drop(columns='y')\n",
    "# 80 training vs. 20 test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)\n",
    "\n",
    "# capping outliers\n",
    "num_cols = ['age','balance','pdays','previous']\n",
    "X_train[num_cols] = X_train[num_cols].astype(float)\n",
    "X_test[num_cols] = X_test[num_cols].astype(float)\n",
    "\n",
    "for col in num_cols:\n",
    "    lower_bound = X_train[col].quantile(0.01)\n",
    "    upper_bound = X_train[col].quantile(0.99)\n",
    "\n",
    "    X_train.loc[:, col] = X_train[col].clip(lower_bound, upper_bound)\n",
    "    X_test.loc[:, col] = X_test[col].clip(lower_bound, upper_bound)\n",
    "\n",
    "# scaling numerical variables\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train[num_cols])\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled.loc[:, num_cols] = scaler.transform(X_train[num_cols])\n",
    "X_test_scaled.loc[:, num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "print(\"--- Data Splitting Verification ---\\n\")\n",
    "print(\"Training set shape:\", X_train_scaled.shape)\n",
    "print(\"Testing set shape:\", X_test_scaled.shape)\n",
    "\n",
    "print(\"\\nSubscription rate in original dataset:\", f\"{y.mean()*100:.2f}%\")\n",
    "print(\"Subscription rate in training dataset:\", f\"{y_train.mean()*100:.2f}%\")\n",
    "print(\"Subscription rate in testing dataset:\", f\"{y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4ec6d",
   "metadata": {},
   "source": [
    "### **Class Imbalance Handling**\n",
    "\n",
    "To prevent model from ignoring the minority class due to the 90/10 imbalance, we will use SMOTE (synthetic minority over-sampling technique) on the training set to create a balanced dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7746ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Class Imbalance Handling ---\n",
      "\n",
      "The original training dataset shape: (3616, 37)\n",
      "Subscription rate in original training dataset: 11.53%\n",
      "\n",
      "Resampled training dataset shape: (6398, 37)\n",
      "Subscription rate in resampled training dataset: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# smote to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"--- Class Imbalance Handling ---\\n\")\n",
    "print(\"The original training dataset shape:\", X_train_scaled.shape)\n",
    "print(\"Subscription rate in original training dataset:\", f\"{y_train.mean()*100:.2f}%\")\n",
    "print(\"\\nResampled training dataset shape:\", X_train_smote.shape)\n",
    "print(\"Subscription rate in resampled training dataset:\", f\"{y_train_smote.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c21be",
   "metadata": {},
   "source": [
    "### **Model Training & Evaluation**\n",
    "\n",
    "In this section, we will develop and evaluate several classification models to predict customer subscriptions. Our modeling strategy will proceed in three key steps:\n",
    "\n",
    "1. **Establish a baseline:** We will begin by building a simple, interpretable model to serve as a solid performance benchmark.\n",
    "\n",
    "2. **Develop advanced models:** We will train more complex models with the goal of outperforming the baseline.\n",
    "\n",
    "3. **Hyperparameter tuning:** Next, the best-perfoming model will be selected and its hyperparameters will be tuned to maximize its predictive power. \n",
    "\n",
    "The models to be trained are:\n",
    "- **Logistic regression:** This will serve as our baseline model. It's a highly interpretable and efficient model that provides a solid benchmark for comparison.\n",
    "\n",
    "- **Random forest and XGBoost:** These are industry-standard ensemble models, which are expected to offer higher predictive performance.\n",
    "\n",
    "Each model's performance will be assessed using **precision**, **recall**, and the **ROC AUC score.** These are optimal metrics for an imbalanced dataset and will help us evaluate the trade-offs relevant to our business objective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17ec64",
   "metadata": {},
   "source": [
    "**Baseline Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f698d8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression Performance ---\n",
      "\n",
      "Accuracy: 0.734\n",
      "Precision: 0.178\n",
      "Recall: 0.365\n",
      "ROC AUC: 0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young/opt/anaconda3/envs/bank_env/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/young/opt/anaconda3/envs/bank_env/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/young/opt/anaconda3/envs/bank_env/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/young/opt/anaconda3/envs/bank_env/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/young/opt/anaconda3/envs/bank_env/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/young/opt/anaconda3/envs/bank_env/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "log_reg = LogisticRegression(random_state=42, solver='saga', penalty='l2', C=0.1, max_iter=5000)\n",
    "# train on the balanced training set\n",
    "log_reg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# prediction on imbalanced test set\n",
    "pred_lr = log_reg.predict(X_test_scaled)\n",
    "# prediction probabilities for 'yes'\n",
    "prob_lr = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"--- Logistic Regression Performance ---\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred_lr):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, pred_lr):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_test, pred_lr):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, prob_lr):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022f1be",
   "metadata": {},
   "source": [
    "*Note on runtime warnings*\n",
    "\n",
    "The logistic regression model produced several RuntimeWarning messages, indicating that its optimization algorithm had difficulty converging, even with scaled data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc6aff",
   "metadata": {},
   "source": [
    "**Baseline Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa294b57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d931ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dd114a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a6fc935",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23622ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6592c1d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03158c96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba8c6edf",
   "metadata": {},
   "source": [
    "### **Identify Best Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e4092",
   "metadata": {},
   "source": [
    "### **Conclusion & Key Insights**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b922ee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
